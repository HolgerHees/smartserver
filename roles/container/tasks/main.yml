#https://kofler.info/docker-unter-centos-8-und-fedora-31-installieren/

- name: install required packages => is_rhel or is_fedora
  yum:
    name: [
        podman
        , hostname
    ]
    state: present
  when: is_rhel or is_fedora

- name: install required packages => is_ubuntu
  apt:
    name: [
        podman
        , hostname
    ]
    state: present
  when: is_ubuntu

#- name: add suse zypper repository
#  zypper_repository:
#    name: Docker
#    repo: 'https://download.opensuse.org/repositories/Virtualization:/containers/{{ansible_distribution_version}}/'
#    auto_import_keys: yes
#    priority: "50"
#    state: present
#  when: is_suse

- name: install required packages => is_suse
  zypper:
    name: [
        podman
        , hostname          # used by container visualizer cli
    ]
    state: present
  when: is_suse

##### DOCKER #####
- name: prepare needed directories
  vars:
    directories:
      - { mode: "u=rwx,g=rx,o=", owner: "root", group: "root", path: "/opt/container" }
      - { mode: "u=rwx,g=rx,o=", owner: "root", group: "root", path: "/opt/container/config" }
      - { mode: "u=rwx,g=rx,o=", owner: "root", group: "root", path: "{{global_lib}}libpod/storage/" }          # podman
      - { mode: "u=rwx,g=rx,o=", owner: "root", group: "root", path: "{{global_lib}}containers/storage/" }      # podman
      - { mode: "u=rwx,g=rx,o=", owner: "root", group: "root", path: "{{global_tmp}}libpod/" }                  # podman
      - { mode: "u=rwx,g=rx,o=", owner: "root", group: "root", path: "{{global_tmp}}containers/storage/" }      # podman
  include_tasks: roles/_shared/create_directories.yml

#- name: set docker selinux configuration => is_rhel or is_fedora
#  sefcontext:
#    target: "{{global_lib}}libpod/storage/"
#    ftype: "d"
#    setype: "container_var_lib_t"
#    seuser: "system_u"
#    state: present
#  with_items:
#    - "{{global_lib}}libpod/storage/"
#    - "{{global_lib}}containers/storage/"
#  register: sefcontext_result
#  when: is_rhel or is_fedora

#- name: reload selinux configuration => (is_rhel or is_fedora) and sefcontext changed
#  shell: "restorecon {{global_lib}}docker"
#  when: (is_rhel or is_fedora) and sefcontext_result.changed

- name: copy podman config
  template:
    src: "templates{{item}}"
    dest: "{{item}}"
    owner: root
    group: root
    mode: 0640
  with_items:
    - "/etc/containers/containers.conf"
    - "/etc/containers/registries.conf"

- name: copy fluentd config
  vars:
    config_file: "templates/etc/fluent/_.ansible.d/podman.conf"
  include_tasks: roles/fluentd/shared/add_config.yml
  tags: ['fluentd_config']
  when: "monitoring_enabled"

- name: synchronize container tools
  synchronize:
    src: "templates/opt/container"
    dest: "/opt/"
    archive: no
    checksum: yes
    group: yes
    owner: yes
    perms: yes
    recursive: yes
    rsync_opts:
      - "--chown=root:root"
      - "--chmod=D750,F750"

- name: copy container tools config
  template:
    src: "templates/config.py"
    dest: "/opt/container/config/config.py"
    owner: root
    group: root
    mode: 0750

#### PODMAN ####
# !!!!remote deployment does not work
#- name: install roles from ansible galaxy
#  local_action: command ansible-galaxy collection install containers.podman
#  register: ag_result
#  changed_when: "'Installing' in ag_result.stdout"

- name: set podman config
  lineinfile:
    path: /etc/containers/{{item.file}}
    regexp: '^{{item.field}}\s*='
    line: '{{item.field}}="{{item.value}}"'
    create: true
    owner: root
    group: root
    mode: 0640
  with_items:
    - { file: 'libpod.conf', field: 'static_dir', value: '{{global_lib}}libpod/storage/' }
    - { file: 'libpod.conf', field: 'tmp_dir', value: '{{global_tmp}}libpod/' }
    - { file: 'libpod.conf', field: 'cgroup_manager', value: "systemd" }
    - { file: 'storage.conf', field: 'driver', value: 'overlay' }
    - { file: 'storage.conf', field: 'runroot', value: '{{global_tmp}}containers/storage/' }
    - { file: 'storage.conf', field: 'graphroot', value: '{{global_lib}}containers/storage/' }


#http://download.opensuse.org/repositories/devel:/kubic/openSUSE_Tumbleweed/x86_64/
#- name: clone dnsname git
#  git:
#    accept_hostkey: yes
#    repo: 'https://github.com/containers/dnsname/'
#    dest: '{{global_build}}podman_dnsname/'
#    version: "master"
#  register: dnsname_git
  
#- name: compile and install dnsname
#  shell: "cd {{global_build}}podman_dnsname/ && make install PREFIX=/usr"
#  when: dnsname_git.changed
#### OTHER ####
    
# https://success.docker.com/article/node-using-swap-memory-instead-of-host-memory
# vm.swappiness = 0   # Swap is disabled. In earlier versions, this meant that the kernel would swap only to avoid an out of memory condition, but in later versions this is achieved by setting to 1.
# vm.swappiness = 1   # Kernel version 3.5 and over, as well as kernel version 2.6.32-303 and over: Minimum amount of swapping without disabling it entirely.
# to clean swap run 'swapoff -a && swapon -a'
- name: set sysctl values for container environments
  lineinfile:
    path: /etc/sysctl.conf
    regexp: '^{{item.regex}}\s*='
    line: '{{item.line}}'
  with_items:
    - { regex: "vm\\.swappiness", line: "vm.swappiness = 1" }
    - { regex: "vm\\.overcommit_memory", line: "vm.overcommit_memory = 1" }

    # IPV4 forwarding is not needed during docker build process. If you get problems, restart firewalld
    #- { regex: "net\\.ipv4\\.ip_forward", line: "net.ipv4.ip_forward = 0" }
  register: sysctlchanged
    
- name: refresh sysctl to activate sysctl changes => sysctl changed
  shell: sysctl -p
  when: sysctlchanged.changed

##### MACVLAN #####
- name: create macvlan network
  containers.podman.podman_network:
    name: 'macvlan'
    ipv6: "{{ 'true' if default_server_ipv6 is defined else 'false' }}"
    driver: macvlan
    opt:
      parent: '{{default_network_interface}}'
    net_config: |
      [
        { "subnet": "{{default_server_network}}", "gateway": "{{default_server_gateway}}" }
        {% if default_server_ipv6 is defined %}
            , { "subnet": "{{default_server_network_ipv6}}", "gateway": "{{default_server_gateway_ipv6}}" }
        {% endif %}
      ]

- name: create isolated podman network
  containers.podman.podman_network:
    name: "isolated"
    internal: no
    ipv6: "{{ 'true' if default_server_ipv6 is defined else 'false' }}"
    subnet: "{{podman_base_network}}/24"
    gateway: "{{podman_base_gateway}}"

- name: copy macvlan_bridge cmd
  template:
    src: "templates/create_macvlan_bridge.sh"
    dest: "/opt/container/create_macvlan_bridge.sh"
    owner: root
    group: root
    mode: 0750
  notify: "restart macvlan_bridge"
  when: "macvlan_range | length > 0"

- name: "create systemd service for 'macvlan_bridge'"
  template:
    src: "templates/macvlan_bridge_service"
    dest: "/etc/systemd/system/macvlan_bridge.service"
    owner: root
    group: root
    mode: 0644
  notify: "restart macvlan_bridge"
  when: "macvlan_range | length > 0"

# ***** FINALIZE *****
- name: register systemd service watcher
  vars:
    name: "macvlan_bridge"
  include_tasks: roles/systemd_watcher/shared/add_watcher.yml
  tags: ['systemd_watcher_config']
  when: "monitoring_enabled and macvlan_range | length > 0"

- name: trigger macvlan_bridge handler
  vars:
    notify: "restart macvlan_bridge"
    service: "macvlan_bridge.service"
  include_tasks: roles/_shared/service_check.yml
  when: "macvlan_range | length > 0"

- name: register systemd service watcher
  vars:
    name: "podman"
  include_tasks: roles/systemd_watcher/shared/add_watcher.yml
  tags: ['systemd_watcher_config']
  when: "monitoring_enabled"

- name: trigger podman handler
  vars:
    notify: "restart podman"
    service: "podman.service"
  include_tasks: roles/_shared/service_check.yml

#- name: register systemd service watcher
#  vars:
#    name: "podman.socket"
#  include_tasks: roles/systemd_watcher/shared/add_watcher.yml
#  tags: ['systemd_watcher_config']
#  when: "monitoring_enabled"

#- name: trigger podman handler
#  vars:
#    notify: "restart podman"
#    service: "podman.socket"
#  include_tasks: roles/_shared/service_check.yml
