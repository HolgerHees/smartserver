 groups:
  - name: alerting
    interval: 60s
    rules:
      - alert: Log error
        expr: |
            sum by (group,log)(
              count_over_time(
                {level="ERROR"}
                # extract the entire log line as a label
                | regexp `(?P<log>(?s).+)`
                [2m]
              )
            )
            > 0.0
        for: 0s
        labels:
            notifyGroup: "logs-{{'{{'}} $labels.group {{'}}'}}"
            severity: error
        annotations:
            url: "https://{{server_domain}}/?ref=admin|system|grafana_logs"

      - alert: Log alert
        expr: |
            sum by (group,log)(
              count_over_time(
                {level="ALERT"}
                # extract the entire log line as a label
                | regexp `(?P<log>(?s).+)`
                [2m]
              )
            )
            > 0.0
        for: 0s
        labels:
            notifyGroup: "logs-{{'{{'}} $labels.group {{'}}'}}"
            severity: critical
        annotations:
            url: "https://{{server_domain}}/?ref=admin|system|grafana_logs"

      - alert: Sendmail not working
        expr: |
            sum by (group) (
              count_over_time(
                {group="postfix"}
                |~ "\\[{{docker_base_gateway | replace('.','\\\\.')}}\\]"
                [24h]
              )
            )
            == 0
        for: 0s
        labels:
            notifyGroup: "postfix"
            severity: critical
        annotations:
            summary: "Sendmail does not work properly. Check postfix deployment."
            url: "https://{{server_domain}}/?ref=admin|system|grafana_logs"
